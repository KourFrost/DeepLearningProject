#ifndef DEFINES_H_
#define DEFINES_H_

#include "ap_int.h"
#include "ap_fixed.h"
#include "nnet_utils/nnet_types.h"
#include <cstddef>
#include <cstdio>

//hls-fpga-machine-learning insert numbers
#define N_INPUT_1_1 Parameter containing:
tensor([-0.2347, -0.1864, -0.2389, -0.2088, -0.2413, -0.2392, -0.4092, -0.3496,
        -0.3000, -0.2374, -0.1872, -0.1686, -0.4206, -0.2737, -0.5745, -0.1949,
        -0.1960, -0.2258, -0.2904, -0.2469, -0.1753, -0.3450, -0.2672, -0.2094,
        -0.2251, -0.3340, -0.2288, -0.3372, -0.2567, -0.3328, -0.2803, -0.2242,
        -0.5383, -3.3427, -0.3597, -0.3646, -0.3803, -0.2576, -0.2421, -0.3502,
        -0.3165, -0.2000, -0.2831, -0.2432, -0.3267, -0.6113, -0.7424, -0.2693,
        -0.3572, -0.2193, -0.2475, -0.1893, -0.4077, -0.3540, -0.2250, -0.4391,
        -0.3596, -0.1976, -0.2901, -1.0702, -0.3184, -0.3957, -0.3969, -0.3716,
        -0.1635, -0.3592, -0.3207, -0.2929, -0.2898, -0.3696, -0.4285, -0.2533,
        -0.2542, -0.2357, -0.2988, -0.2747, -0.2109, -0.3383, -0.3382, -0.2383,
        -0.2475, -0.5913, -0.3366, -0.2294, -0.3380, -0.1763, -0.3606, -0.3602,
        -0.2401, -0.3935,  0.0268,  0.0167, -0.2422, -0.2878, -0.2376, -0.2801,
        -0.1960, -0.2946, -0.2155, -0.6346, -0.9313, -0.3015, -0.2108, -0.2434,
        -0.2352, -0.3197, -0.3025, -0.1331, -0.4037, -0.1717, -0.2702, -0.3204,
        -0.3117, -0.3182, -0.3583, -0.3952, -0.4118, -0.4467, -0.2696, -0.2927,
        -0.1948, -0.2260, -0.2361, -0.0980, -0.3340, -0.2683, -0.0750, -0.2222,
        -0.2045, -0.2272, -0.4379, -0.1761, -0.1904, -0.1835, -0.3944, -0.3130,
        -0.2518, -0.3145, -0.3376, -0.2018, -0.2106, -0.2593, -0.3454, -0.2647,
        -0.2646, -0.3506, -0.6335, -0.3020, -0.3571, -0.8287, -0.2757, -0.2433,
         0.3383, -0.2032, -0.3273, -0.2354, -0.1711, -0.3210, -0.3511,  0.0488,
        -0.3112, -0.2411, -0.3096, -0.1001, -0.2238, -0.2415, -0.1923, -0.3311,
        -0.3653, -0.3987, -0.2799, -0.1787, -0.3962, -0.6396, -0.1897, -0.1934,
        -0.2019, -0.1603, -0.2038, -0.2097, -0.3578, -0.2534,  2.0057, -0.2220,
        -0.3147, -0.2968, -0.3189, -0.3245, -0.1526, -0.9459, -0.3908, -0.2655,
        -0.4650, -0.3441, -0.3849, -0.2659, -0.3284, -0.1724, -0.3228, -0.5824,
        -0.2660, -0.1509, -0.2097, -0.2637, -0.5328, -0.3888, -0.3951, -0.3641,
        -0.6408, -0.2304, -0.2198, -0.3116, -0.2246, -0.3434, -0.2367, -0.1251,
        -0.4203, -0.3377,  0.0180, -1.0034, -0.2616, -0.3210, -0.2602, -0.2293,
        -0.3756, -0.3356, -0.3049, -0.2440, -0.1473, -0.2460, -0.1141,  0.7758,
        -0.4286, -0.3247, -0.1553, -0.2972, -0.2352, -0.3354, -0.1932, -0.1768,
        -0.1755, -0.1347, -0.2582, -0.2354, -0.4395, -0.1499, -0.1046, -0.5301,
        -0.4272, -0.3916, -0.3643, -0.0479, -0.1829, -0.3208, -0.3113, -0.3998,
        -0.2903, -0.1962, -0.3237, -0.3696, -0.2759, -0.2480, -0.3389, -0.3112,
        -0.1879, -0.4409, -0.2728, -0.2178, -0.2315,  0.4779, -0.2374, -0.4954,
        -0.5919, -0.1126, -0.0544, -0.1692, -0.6097, -0.7218, -0.2122, -0.3918,
        -0.3332, -0.2834, -0.4315, -0.2962, -0.1211, -0.3389, -0.2301, -0.3488,
        -0.4230, -0.2640, -0.2525, -0.4144, -0.4185, -0.4401, -0.3407, -0.2418,
        -0.2079, -0.5050, -0.3313, -0.1835, -0.2059, -0.3942, -0.2483, -0.1660,
        -0.3523, -0.2440, -0.3651, -0.3078, -0.3817, -0.3237, -0.2765, -0.3514,
        -0.3979, -0.3493, -0.3031, -0.3724, -0.2685, -0.2720, -0.8172, -0.6024,
        -0.8041, -0.3917, -0.8615, -0.3143, -0.1988, -0.2656, -0.2590, -0.3371,
        -0.5446, -0.2249, -0.3415, -0.2470, -0.2880, -0.3949, -0.3344, -0.3738,
        -0.3380, -0.7387, -0.2107, -0.8937, -0.3202, -0.4020, -0.1856, -0.3988,
        -0.0641, -0.0328, -0.3345, -0.3343, -0.5449, -0.2731, -0.3308, -0.3480,
        -0.3284, -0.3231, -0.3140, -0.3697, -0.3223, -0.1399, -0.2144, -0.2329,
        -0.3626, -0.4609, -0.1668, -0.2949, -0.2551, -0.3258, -0.1943, -0.3622,
        -0.2313, -0.3735, -0.2831, -0.2474, -0.3881,  0.0568, -0.3980, -0.1734,
        -0.4007, -0.3481, -0.1792, -0.2828, -0.3734, -0.3273, -0.2855, -0.3677,
        -0.4194, -0.3624, -0.3918, -1.0140, -0.3989, -0.2136, -0.2164, -0.2029,
        -0.5360, -0.1998, -1.0766, -0.3758, -0.2444, -0.3448, -0.9548, -0.2237,
        -0.1543, -0.3208, -0.2996, -0.2954, -0.3437, -0.8373, -0.2268, -0.4156,
        -0.1840, -0.3009, -0.3397, -0.1725, -0.2982, -0.2846, -0.2015, -0.2889,
        -0.2976, -0.3010, -0.2502, -0.1899, -0.1697, -0.2236, -0.3792, -0.1515,
        -0.2326, -0.3353, -0.2518, -0.3381, -0.3078, -0.4813, -0.3906, -0.2564,
        -0.2228, -0.2346, -0.1685, -0.2655, -0.3842, -0.1862, -0.3260, -0.2099,
        -0.1987, -0.1812, -0.3333, -0.2290,  0.0080, -0.3633, -0.2088, -0.3259,
        -1.5440, -0.2311, -1.4321, -0.3038,  0.0045, -0.2444, -0.3268, -0.2865,
        -0.2296, -0.2841, -0.1639, -0.3006, -0.2260,  0.6774, -0.3474, -0.2785,
        -0.3838, -0.2408, -0.1499,  0.9536, -0.1543, -0.2444, -0.3252, -0.2195,
        -0.3962, -0.1796, -0.4832, -0.2984, -0.8150, -0.2625, -0.1684, -0.3709,
        -0.1977, -0.3087, -0.6342,  0.0364, -0.4432, -0.2533, -0.1617, -0.2263,
        -0.3602, -0.1863, -0.2439, -0.2672, -0.2128, -0.2174, -0.2197, -0.4390,
        -0.1915, -0.5484, -0.2027, -0.2550, -0.2494, -0.2233, -0.1104, -0.1760,
        -0.2843, -0.2408, -0.5889, -0.2857,  0.4262, -0.2986, -0.2346, -0.2473],
       requires_grad=True)
#define N_INPUT_2_1 Parameter containing:
tensor([[ 0.1247, -0.1566, -0.1755,  ...,  0.2006, -0.1618, -0.2251],
        [ 0.0311, -0.2661,  0.1681,  ..., -0.2147,  0.2000,  0.3776],
        [-0.0873, -0.2698,  0.1192,  ..., -0.1177,  0.2011,  0.2497],
        ...,
        [-0.0512,  0.3464,  0.2153,  ...,  0.3837,  0.2056,  0.3349],
        [ 0.2557, -0.3174, -0.0311,  ...,  0.2354,  0.1891,  0.2150],
        [ 0.3440,  0.4351,  0.1224,  ...,  0.0425,  0.1898,  0.1513]],
       requires_grad=True)
#define N_INPUT_3_1 Parameter containing:
tensor([ 0.6146, -1.1204,  0.3844,  0.5228, -0.2767, -0.0711, -0.9121, -0.9339,
         1.1184,  0.3993], requires_grad=True)
#define OUT_HEIGHT_4 Parameter containing:
tensor([-0.2347, -0.1864, -0.2389, -0.2088, -0.2413, -0.2392, -0.4092, -0.3496,
        -0.3000, -0.2374, -0.1872, -0.1686, -0.4206, -0.2737, -0.5745, -0.1949,
        -0.1960, -0.2258, -0.2904, -0.2469, -0.1753, -0.3450, -0.2672, -0.2094,
        -0.2251, -0.3340, -0.2288, -0.3372, -0.2567, -0.3328, -0.2803, -0.2242,
        -0.5383, -3.3427, -0.3597, -0.3646, -0.3803, -0.2576, -0.2421, -0.3502,
        -0.3165, -0.2000, -0.2831, -0.2432, -0.3267, -0.6113, -0.7424, -0.2693,
        -0.3572, -0.2193, -0.2475, -0.1893, -0.4077, -0.3540, -0.2250, -0.4391,
        -0.3596, -0.1976, -0.2901, -1.0702, -0.3184, -0.3957, -0.3969, -0.3716,
        -0.1635, -0.3592, -0.3207, -0.2929, -0.2898, -0.3696, -0.4285, -0.2533,
        -0.2542, -0.2357, -0.2988, -0.2747, -0.2109, -0.3383, -0.3382, -0.2383,
        -0.2475, -0.5913, -0.3366, -0.2294, -0.3380, -0.1763, -0.3606, -0.3602,
        -0.2401, -0.3935,  0.0268,  0.0167, -0.2422, -0.2878, -0.2376, -0.2801,
        -0.1960, -0.2946, -0.2155, -0.6346, -0.9313, -0.3015, -0.2108, -0.2434,
        -0.2352, -0.3197, -0.3025, -0.1331, -0.4037, -0.1717, -0.2702, -0.3204,
        -0.3117, -0.3182, -0.3583, -0.3952, -0.4118, -0.4467, -0.2696, -0.2927,
        -0.1948, -0.2260, -0.2361, -0.0980, -0.3340, -0.2683, -0.0750, -0.2222,
        -0.2045, -0.2272, -0.4379, -0.1761, -0.1904, -0.1835, -0.3944, -0.3130,
        -0.2518, -0.3145, -0.3376, -0.2018, -0.2106, -0.2593, -0.3454, -0.2647,
        -0.2646, -0.3506, -0.6335, -0.3020, -0.3571, -0.8287, -0.2757, -0.2433,
         0.3383, -0.2032, -0.3273, -0.2354, -0.1711, -0.3210, -0.3511,  0.0488,
        -0.3112, -0.2411, -0.3096, -0.1001, -0.2238, -0.2415, -0.1923, -0.3311,
        -0.3653, -0.3987, -0.2799, -0.1787, -0.3962, -0.6396, -0.1897, -0.1934,
        -0.2019, -0.1603, -0.2038, -0.2097, -0.3578, -0.2534,  2.0057, -0.2220,
        -0.3147, -0.2968, -0.3189, -0.3245, -0.1526, -0.9459, -0.3908, -0.2655,
        -0.4650, -0.3441, -0.3849, -0.2659, -0.3284, -0.1724, -0.3228, -0.5824,
        -0.2660, -0.1509, -0.2097, -0.2637, -0.5328, -0.3888, -0.3951, -0.3641,
        -0.6408, -0.2304, -0.2198, -0.3116, -0.2246, -0.3434, -0.2367, -0.1251,
        -0.4203, -0.3377,  0.0180, -1.0034, -0.2616, -0.3210, -0.2602, -0.2293,
        -0.3756, -0.3356, -0.3049, -0.2440, -0.1473, -0.2460, -0.1141,  0.7758,
        -0.4286, -0.3247, -0.1553, -0.2972, -0.2352, -0.3354, -0.1932, -0.1768,
        -0.1755, -0.1347, -0.2582, -0.2354, -0.4395, -0.1499, -0.1046, -0.5301,
        -0.4272, -0.3916, -0.3643, -0.0479, -0.1829, -0.3208, -0.3113, -0.3998,
        -0.2903, -0.1962, -0.3237, -0.3696, -0.2759, -0.2480, -0.3389, -0.3112,
        -0.1879, -0.4409, -0.2728, -0.2178, -0.2315,  0.4779, -0.2374, -0.4954,
        -0.5919, -0.1126, -0.0544, -0.1692, -0.6097, -0.7218, -0.2122, -0.3918,
        -0.3332, -0.2834, -0.4315, -0.2962, -0.1211, -0.3389, -0.2301, -0.3488,
        -0.4230, -0.2640, -0.2525, -0.4144, -0.4185, -0.4401, -0.3407, -0.2418,
        -0.2079, -0.5050, -0.3313, -0.1835, -0.2059, -0.3942, -0.2483, -0.1660,
        -0.3523, -0.2440, -0.3651, -0.3078, -0.3817, -0.3237, -0.2765, -0.3514,
        -0.3979, -0.3493, -0.3031, -0.3724, -0.2685, -0.2720, -0.8172, -0.6024,
        -0.8041, -0.3917, -0.8615, -0.3143, -0.1988, -0.2656, -0.2590, -0.3371,
        -0.5446, -0.2249, -0.3415, -0.2470, -0.2880, -0.3949, -0.3344, -0.3738,
        -0.3380, -0.7387, -0.2107, -0.8937, -0.3202, -0.4020, -0.1856, -0.3988,
        -0.0641, -0.0328, -0.3345, -0.3343, -0.5449, -0.2731, -0.3308, -0.3480,
        -0.3284, -0.3231, -0.3140, -0.3697, -0.3223, -0.1399, -0.2144, -0.2329,
        -0.3626, -0.4609, -0.1668, -0.2949, -0.2551, -0.3258, -0.1943, -0.3622,
        -0.2313, -0.3735, -0.2831, -0.2474, -0.3881,  0.0568, -0.3980, -0.1734,
        -0.4007, -0.3481, -0.1792, -0.2828, -0.3734, -0.3273, -0.2855, -0.3677,
        -0.4194, -0.3624, -0.3918, -1.0140, -0.3989, -0.2136, -0.2164, -0.2029,
        -0.5360, -0.1998, -1.0766, -0.3758, -0.2444, -0.3448, -0.9548, -0.2237,
        -0.1543, -0.3208, -0.2996, -0.2954, -0.3437, -0.8373, -0.2268, -0.4156,
        -0.1840, -0.3009, -0.3397, -0.1725, -0.2982, -0.2846, -0.2015, -0.2889,
        -0.2976, -0.3010, -0.2502, -0.1899, -0.1697, -0.2236, -0.3792, -0.1515,
        -0.2326, -0.3353, -0.2518, -0.3381, -0.3078, -0.4813, -0.3906, -0.2564,
        -0.2228, -0.2346, -0.1685, -0.2655, -0.3842, -0.1862, -0.3260, -0.2099,
        -0.1987, -0.1812, -0.3333, -0.2290,  0.0080, -0.3633, -0.2088, -0.3259,
        -1.5440, -0.2311, -1.4321, -0.3038,  0.0045, -0.2444, -0.3268, -0.2865,
        -0.2296, -0.2841, -0.1639, -0.3006, -0.2260,  0.6774, -0.3474, -0.2785,
        -0.3838, -0.2408, -0.1499,  0.9536, -0.1543, -0.2444, -0.3252, -0.2195,
        -0.3962, -0.1796, -0.4832, -0.2984, -0.8150, -0.2625, -0.1684, -0.3709,
        -0.1977, -0.3087, -0.6342,  0.0364, -0.4432, -0.2533, -0.1617, -0.2263,
        -0.3602, -0.1863, -0.2439, -0.2672, -0.2128, -0.2174, -0.2197, -0.4390,
        -0.1915, -0.5484, -0.2027, -0.2550, -0.2494, -0.2233, -0.1104, -0.1760,
        -0.2843, -0.2408, -0.5889, -0.2857,  0.4262, -0.2986, -0.2346, -0.2473],
       requires_grad=True)
#define OUT_WIDTH_4 Parameter containing:
tensor([[ 0.1247, -0.1566, -0.1755,  ...,  0.2006, -0.1618, -0.2251],
        [ 0.0311, -0.2661,  0.1681,  ..., -0.2147,  0.2000,  0.3776],
        [-0.0873, -0.2698,  0.1192,  ..., -0.1177,  0.2011,  0.2497],
        ...,
        [-0.0512,  0.3464,  0.2153,  ...,  0.3837,  0.2056,  0.3349],
        [ 0.2557, -0.3174, -0.0311,  ...,  0.2354,  0.1891,  0.2150],
        [ 0.3440,  0.4351,  0.1224,  ...,  0.0425,  0.1898,  0.1513]],
       requires_grad=True)
#define N_FILT_4 512
#define OUT_HEIGHT_5 Parameter containing:
tensor([-0.2347, -0.1864, -0.2389, -0.2088, -0.2413, -0.2392, -0.4092, -0.3496,
        -0.3000, -0.2374, -0.1872, -0.1686, -0.4206, -0.2737, -0.5745, -0.1949,
        -0.1960, -0.2258, -0.2904, -0.2469, -0.1753, -0.3450, -0.2672, -0.2094,
        -0.2251, -0.3340, -0.2288, -0.3372, -0.2567, -0.3328, -0.2803, -0.2242,
        -0.5383, -3.3427, -0.3597, -0.3646, -0.3803, -0.2576, -0.2421, -0.3502,
        -0.3165, -0.2000, -0.2831, -0.2432, -0.3267, -0.6113, -0.7424, -0.2693,
        -0.3572, -0.2193, -0.2475, -0.1893, -0.4077, -0.3540, -0.2250, -0.4391,
        -0.3596, -0.1976, -0.2901, -1.0702, -0.3184, -0.3957, -0.3969, -0.3716,
        -0.1635, -0.3592, -0.3207, -0.2929, -0.2898, -0.3696, -0.4285, -0.2533,
        -0.2542, -0.2357, -0.2988, -0.2747, -0.2109, -0.3383, -0.3382, -0.2383,
        -0.2475, -0.5913, -0.3366, -0.2294, -0.3380, -0.1763, -0.3606, -0.3602,
        -0.2401, -0.3935,  0.0268,  0.0167, -0.2422, -0.2878, -0.2376, -0.2801,
        -0.1960, -0.2946, -0.2155, -0.6346, -0.9313, -0.3015, -0.2108, -0.2434,
        -0.2352, -0.3197, -0.3025, -0.1331, -0.4037, -0.1717, -0.2702, -0.3204,
        -0.3117, -0.3182, -0.3583, -0.3952, -0.4118, -0.4467, -0.2696, -0.2927,
        -0.1948, -0.2260, -0.2361, -0.0980, -0.3340, -0.2683, -0.0750, -0.2222,
        -0.2045, -0.2272, -0.4379, -0.1761, -0.1904, -0.1835, -0.3944, -0.3130,
        -0.2518, -0.3145, -0.3376, -0.2018, -0.2106, -0.2593, -0.3454, -0.2647,
        -0.2646, -0.3506, -0.6335, -0.3020, -0.3571, -0.8287, -0.2757, -0.2433,
         0.3383, -0.2032, -0.3273, -0.2354, -0.1711, -0.3210, -0.3511,  0.0488,
        -0.3112, -0.2411, -0.3096, -0.1001, -0.2238, -0.2415, -0.1923, -0.3311,
        -0.3653, -0.3987, -0.2799, -0.1787, -0.3962, -0.6396, -0.1897, -0.1934,
        -0.2019, -0.1603, -0.2038, -0.2097, -0.3578, -0.2534,  2.0057, -0.2220,
        -0.3147, -0.2968, -0.3189, -0.3245, -0.1526, -0.9459, -0.3908, -0.2655,
        -0.4650, -0.3441, -0.3849, -0.2659, -0.3284, -0.1724, -0.3228, -0.5824,
        -0.2660, -0.1509, -0.2097, -0.2637, -0.5328, -0.3888, -0.3951, -0.3641,
        -0.6408, -0.2304, -0.2198, -0.3116, -0.2246, -0.3434, -0.2367, -0.1251,
        -0.4203, -0.3377,  0.0180, -1.0034, -0.2616, -0.3210, -0.2602, -0.2293,
        -0.3756, -0.3356, -0.3049, -0.2440, -0.1473, -0.2460, -0.1141,  0.7758,
        -0.4286, -0.3247, -0.1553, -0.2972, -0.2352, -0.3354, -0.1932, -0.1768,
        -0.1755, -0.1347, -0.2582, -0.2354, -0.4395, -0.1499, -0.1046, -0.5301,
        -0.4272, -0.3916, -0.3643, -0.0479, -0.1829, -0.3208, -0.3113, -0.3998,
        -0.2903, -0.1962, -0.3237, -0.3696, -0.2759, -0.2480, -0.3389, -0.3112,
        -0.1879, -0.4409, -0.2728, -0.2178, -0.2315,  0.4779, -0.2374, -0.4954,
        -0.5919, -0.1126, -0.0544, -0.1692, -0.6097, -0.7218, -0.2122, -0.3918,
        -0.3332, -0.2834, -0.4315, -0.2962, -0.1211, -0.3389, -0.2301, -0.3488,
        -0.4230, -0.2640, -0.2525, -0.4144, -0.4185, -0.4401, -0.3407, -0.2418,
        -0.2079, -0.5050, -0.3313, -0.1835, -0.2059, -0.3942, -0.2483, -0.1660,
        -0.3523, -0.2440, -0.3651, -0.3078, -0.3817, -0.3237, -0.2765, -0.3514,
        -0.3979, -0.3493, -0.3031, -0.3724, -0.2685, -0.2720, -0.8172, -0.6024,
        -0.8041, -0.3917, -0.8615, -0.3143, -0.1988, -0.2656, -0.2590, -0.3371,
        -0.5446, -0.2249, -0.3415, -0.2470, -0.2880, -0.3949, -0.3344, -0.3738,
        -0.3380, -0.7387, -0.2107, -0.8937, -0.3202, -0.4020, -0.1856, -0.3988,
        -0.0641, -0.0328, -0.3345, -0.3343, -0.5449, -0.2731, -0.3308, -0.3480,
        -0.3284, -0.3231, -0.3140, -0.3697, -0.3223, -0.1399, -0.2144, -0.2329,
        -0.3626, -0.4609, -0.1668, -0.2949, -0.2551, -0.3258, -0.1943, -0.3622,
        -0.2313, -0.3735, -0.2831, -0.2474, -0.3881,  0.0568, -0.3980, -0.1734,
        -0.4007, -0.3481, -0.1792, -0.2828, -0.3734, -0.3273, -0.2855, -0.3677,
        -0.4194, -0.3624, -0.3918, -1.0140, -0.3989, -0.2136, -0.2164, -0.2029,
        -0.5360, -0.1998, -1.0766, -0.3758, -0.2444, -0.3448, -0.9548, -0.2237,
        -0.1543, -0.3208, -0.2996, -0.2954, -0.3437, -0.8373, -0.2268, -0.4156,
        -0.1840, -0.3009, -0.3397, -0.1725, -0.2982, -0.2846, -0.2015, -0.2889,
        -0.2976, -0.3010, -0.2502, -0.1899, -0.1697, -0.2236, -0.3792, -0.1515,
        -0.2326, -0.3353, -0.2518, -0.3381, -0.3078, -0.4813, -0.3906, -0.2564,
        -0.2228, -0.2346, -0.1685, -0.2655, -0.3842, -0.1862, -0.3260, -0.2099,
        -0.1987, -0.1812, -0.3333, -0.2290,  0.0080, -0.3633, -0.2088, -0.3259,
        -1.5440, -0.2311, -1.4321, -0.3038,  0.0045, -0.2444, -0.3268, -0.2865,
        -0.2296, -0.2841, -0.1639, -0.3006, -0.2260,  0.6774, -0.3474, -0.2785,
        -0.3838, -0.2408, -0.1499,  0.9536, -0.1543, -0.2444, -0.3252, -0.2195,
        -0.3962, -0.1796, -0.4832, -0.2984, -0.8150, -0.2625, -0.1684, -0.3709,
        -0.1977, -0.3087, -0.6342,  0.0364, -0.4432, -0.2533, -0.1617, -0.2263,
        -0.3602, -0.1863, -0.2439, -0.2672, -0.2128, -0.2174, -0.2197, -0.4390,
        -0.1915, -0.5484, -0.2027, -0.2550, -0.2494, -0.2233, -0.1104, -0.1760,
        -0.2843, -0.2408, -0.5889, -0.2857,  0.4262, -0.2986, -0.2346, -0.2473],
       requires_grad=True)
#define OUT_WIDTH_5 Parameter containing:
tensor([[ 0.1247, -0.1566, -0.1755,  ...,  0.2006, -0.1618, -0.2251],
        [ 0.0311, -0.2661,  0.1681,  ..., -0.2147,  0.2000,  0.3776],
        [-0.0873, -0.2698,  0.1192,  ..., -0.1177,  0.2011,  0.2497],
        ...,
        [-0.0512,  0.3464,  0.2153,  ...,  0.3837,  0.2056,  0.3349],
        [ 0.2557, -0.3174, -0.0311,  ...,  0.2354,  0.1891,  0.2150],
        [ 0.3440,  0.4351,  0.1224,  ...,  0.0425,  0.1898,  0.1513]],
       requires_grad=True)
#define N_FILT_5 10

//hls-fpga-machine-learning insert layer-precision
typedef ap_fixed<16,6> model_default_t;
typedef ap_fixed<16,6> input_t;
typedef ap_fixed<16,6> layer4_t;
typedef ap_fixed<16,6> result_t;

#endif
